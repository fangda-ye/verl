# SFT Warmup + RL Training Pipeline

å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼šå…ˆç”¨ SFT æ•°æ®åšå†·å¯åŠ¨ï¼Œç„¶åç»§ç»­ RL è®­ç»ƒã€‚

## ğŸ“Š æ•°æ®è¯´æ˜

### ä¸¤ç§æ•°æ®æ ¼å¼

#### 1. SFT æ•°æ®ï¼ˆ`sampleQA_processed_2.jsonl`ï¼‰

åŒ…å«å®Œæ•´çš„å¯¹è¯ï¼Œå¸¦æœ‰ `<think>` å’Œ `<proactive>` æ ‡ç­¾ï¼š

```json
{
  "messages": [
    {"role": "system", "content": "You are a helpful proactive assistant."},
    {"role": "user", "content": "How much money, in euros, was the surgeon...?"},
    {"role": "assistant", "content": "<think>\n...\n</think>\n\n<proactive>\n...\n</proactive>\n\nI don't have the exact financial details..."}
  ],
  "id": 5,
  "sub_category": "simpleQA"
}
```

**ç”¨é€”**ï¼š
- æ•™ä¼šæ¨¡å‹ä½¿ç”¨ `<think>` å’Œ `<proactive>` æ ‡ç­¾
- å†·å¯åŠ¨è®­ç»ƒï¼Œæä¾›åˆå§‹èƒ½åŠ›
- éšæœºæŠ½å– 50 æ¡ç”¨äº SFT

#### 2. RL æ•°æ®ï¼ˆ`sampleQA.jsonl`ï¼‰

åªåŒ…å« user é—®é¢˜å’Œç®€å•ç­”æ¡ˆï¼ˆground truthï¼‰ï¼š

```json
{
  "id": 0,
  "messages": [
    {"role": "user", "content": "Who received the IEEE Frank Rosenblatt Award in 2010?"},
    {"role": "assistant", "content": "Michio Sugeno"}
  ],
  "answer": {...},
  "sub_category": "simpleQA"
}
```

**ç”¨é€”**ï¼š
- RL è®­ç»ƒçš„ prompt æ¥æº
- åªä½¿ç”¨ user é—®é¢˜ä½œä¸º prompt
- assistant ç­”æ¡ˆä½œä¸º ground truth ç”¨äº reward è®¡ç®—

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ 1ï¼šä¸€é”®è¿è¡Œï¼ˆæ¨èï¼‰

å®Œæ•´æµç¨‹è‡ªåŠ¨åŒ–ï¼šSFT â†’ RL

```bash
bash examples/proactive/run_sft_then_rl.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. âœ… ä» `data/sampleQA_processed_2.jsonl` éšæœºæŠ½å– 50 æ¡
2. âœ… è¿è¡Œ SFT è®­ç»ƒï¼ˆ2 epochsï¼‰
3. âœ… åŠ è½½ SFT checkpoint
4. âœ… å¤„ç† `data/sampleQA.jsonl` ç”¨äº RL
5. âœ… è¿è¡Œ RL è®­ç»ƒï¼ˆ10 epochsï¼‰

### æ–¹å¼ 2ï¼šåˆ†æ­¥è¿è¡Œ

#### æ­¥éª¤ 1ï¼šSFT å†·å¯åŠ¨

```bash
bash examples/proactive/run_sft_warmup.sh
```

è¿™ä¼šï¼š
- éšæœºæŠ½å– 50 æ¡ SFT æ•°æ®
- è®­ç»ƒ 2 epochs
- ä¿å­˜ checkpoint åˆ° `checkpoints/proactive_sft_warmup/`

#### æ­¥éª¤ 2ï¼šRL è®­ç»ƒ

ä½¿ç”¨ SFT checkpoint ç»§ç»­è®­ç»ƒï¼š

```bash
# æ–¹å¼ Aï¼šæ‰‹åŠ¨æŒ‡å®š checkpoint
bash examples/proactive/run_proactive_grpo.sh \
    actor_rollout_ref.model.path='checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/epoch_2'

# æ–¹å¼ Bï¼šä»åŸºç¡€æ¨¡å‹å¼€å§‹ï¼ˆä¸æ¨èï¼Œè·³è¿‡ SFTï¼‰
bash examples/proactive/run_proactive_grpo.sh
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
examples/proactive/
â”œâ”€â”€ process_sft_data.py              # å¤„ç† SFT æ•°æ®ï¼ˆéšæœºæŠ½æ ·ï¼‰
â”œâ”€â”€ process_sampleQA.py              # å¤„ç† RL æ•°æ®
â”œâ”€â”€ group_aware_reward.py            # å¥–åŠ±å‡½æ•°
â”œâ”€â”€ run_sft_warmup.sh                # åªè¿è¡Œ SFT
â”œâ”€â”€ run_proactive_grpo.sh            # åªè¿è¡Œ RL
â”œâ”€â”€ run_sft_then_rl.sh               # å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
â””â”€â”€ README_SFT_RL.md                 # æœ¬æ–‡æ¡£

data/
â”œâ”€â”€ sampleQA_processed_2.jsonl       # SFT æ•°æ®æºï¼ˆå¸¦æ ‡ç­¾çš„å®Œæ•´å›ç­”ï¼‰
â”œâ”€â”€ sampleQA.jsonl                   # RL æ•°æ®æºï¼ˆç®€å• QAï¼‰
â”œâ”€â”€ sft_samples.jsonl                # æŠ½å–çš„ 50 æ¡ SFT æ•°æ®
â””â”€â”€ processed_sampleQA/              # å¤„ç†åçš„ RL æ•°æ®
    â”œâ”€â”€ train.parquet
    â””â”€â”€ test.parquet

checkpoints/
â”œâ”€â”€ proactive_sft_warmup/            # SFT checkpoints
â”‚   â””â”€â”€ sft_50_samples/
â”‚       â””â”€â”€ checkpoints/
â”‚           â””â”€â”€ epoch_2/             # ç”¨è¿™ä¸ªç»§ç»­ RL
â””â”€â”€ proactive_agent/                 # RL checkpoints
    â””â”€â”€ sft50_rl_beta0.5_n16/
```

## âš™ï¸ é…ç½®å‚æ•°

### SFT é…ç½®

åœ¨ `run_sft_then_rl.sh` ä¸­ä¿®æ”¹ï¼š

```bash
NUM_SFT_SAMPLES=50      # SFT æ•°æ®æ•°é‡ï¼ˆé»˜è®¤ 50ï¼‰
SFT_EPOCHS=2            # SFT è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 2ï¼‰
```

### RL é…ç½®

```bash
RL_BETA=0.5             # Proactive å¥–åŠ±æƒé‡ï¼ˆ0.0-1.0ï¼‰
RL_ROLLOUTS=16          # æ¯ä¸ª prompt çš„ rollouts æ•°é‡
RL_EPOCHS=10            # RL è®­ç»ƒè½®æ•°
```

### æ¨¡å‹è·¯å¾„

```bash
BASE_MODEL_PATH="/mnt/hdd/Fangda/data/models/qwen3-8b"
```

## ğŸ¯ è®­ç»ƒæµç¨‹è¯¦è§£

### Stage 1: SFT Warmup

**ç›®æ ‡**ï¼šæ•™ä¼šæ¨¡å‹ä½¿ç”¨ `<think>` å’Œ `<proactive>` æ ‡ç­¾

**æ•°æ®**ï¼š
- è¾“å…¥ï¼š50 æ¡å®Œæ•´çš„å¯¹è¯ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰
- è®­ç»ƒæ–¹å¼ï¼šæ ‡å‡†çš„ supervised fine-tuning

**è¾“å‡º**ï¼š
- Checkpointï¼š`checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/epoch_2/`
- æ¨¡å‹å·²ç»å­¦ä¼šï¼š
  - ä½¿ç”¨ `<think>` æ ‡ç­¾æ€è€ƒ
  - ä½¿ç”¨ `<proactive>` æ ‡ç­¾åšä¸»åŠ¨æ¨ç†
  - åŸºæœ¬çš„å›ç­”æ ¼å¼

### Stage 2: RL Training

**ç›®æ ‡**ï¼šé€šè¿‡ group-aware rewards ä¼˜åŒ–ç”Ÿæˆè´¨é‡

**æ•°æ®**ï¼š
- è¾“å…¥ï¼šåªæœ‰ user é—®é¢˜ï¼ˆæ— æ ‡ç­¾ç¤ºä¾‹ï¼‰
- Ground truthï¼šç®€å•ç­”æ¡ˆï¼ˆç”¨äº reward è®¡ç®—ï¼‰

**å¥–åŠ±ç­–ç•¥**ï¼š
- æ­£ç¡®æ€§ï¼šåªæ£€æŸ¥æ­£å¼å›ç­”éƒ¨åˆ†ï¼ˆç§»é™¤æ ‡ç­¾å†…å®¹ï¼‰
- æ ¼å¼å¥–åŠ±ï¼šä½¿ç”¨ `<think>` å’Œ `<proactive>` æ ‡ç­¾
- Proactive å¥–åŠ±ï¼šéš¾é¢˜ï¼ˆä½ group accï¼‰è·å¾—æ›´é«˜å¥–åŠ±

**è¾“å‡º**ï¼š
- Checkpointï¼š`checkpoints/proactive_agent/sft50_rl_beta0.5_n16/`
- æ¨¡å‹å·²ç»å­¦ä¼šï¼š
  - åœ¨åˆé€‚çš„æ—¶å€™ä½¿ç”¨ proactive æ€è€ƒ
  - æ ¹æ®é—®é¢˜éš¾åº¦è°ƒæ•´ç­–ç•¥
  - ç”Ÿæˆé«˜è´¨é‡çš„ç»“æ„åŒ–å›ç­”

## ğŸ“Š ä¸ºä»€ä¹ˆéœ€è¦ SFT å†·å¯åŠ¨ï¼Ÿ

### é—®é¢˜ï¼šç›´æ¥ RL è®­ç»ƒ

å¦‚æœç›´æ¥ä»åŸºç¡€æ¨¡å‹å¼€å§‹ RLï¼š
- âŒ æ¨¡å‹ä¸çŸ¥é“ `<think>` å’Œ `<proactive>` æ ‡ç­¾
- âŒ æ— æ³•ç”Ÿæˆç»“æ„åŒ–çš„å›ç­”
- âŒ RL è®­ç»ƒæ•ˆæœå·®ï¼Œéš¾ä»¥æ”¶æ•›

### è§£å†³æ–¹æ¡ˆï¼šSFT â†’ RL

å…ˆç”¨ SFT æ•™ä¼šæ¨¡å‹æ ¼å¼ï¼š
- âœ… æ¨¡å‹å­¦ä¼šä½¿ç”¨æ ‡ç­¾
- âœ… ç†è§£ä»€ä¹ˆæ˜¯ proactive æ€è€ƒ
- âœ… RL è®­ç»ƒå¯ä»¥åœ¨è‰¯å¥½çš„åŸºç¡€ä¸Šä¼˜åŒ–

## ğŸ”§ è‡ªå®šä¹‰å‚æ•°

### ä¿®æ”¹ SFT æ ·æœ¬æ•°é‡

```bash
bash examples/proactive/run_sft_then_rl.sh
# ç¼–è¾‘è„šæœ¬ï¼Œä¿®æ”¹ NUM_SFT_SAMPLES=100
```

### ä¿®æ”¹ RL å‚æ•°

```bash
# ä¿®æ”¹ beta å€¼
bash examples/proactive/run_sft_then_rl.sh \
    custom_reward_function.reward_kwargs.beta=0.7

# ä¿®æ”¹ rollout æ•°é‡
bash examples/proactive/run_sft_then_rl.sh \
    actor_rollout_ref.rollout.n=8

# ä¿®æ”¹è®­ç»ƒè½®æ•°
bash examples/proactive/run_sft_then_rl.sh \
    trainer.total_epochs=20
```

### åªè¿è¡Œ SFTï¼ˆä¸æ¥ RLï¼‰

```bash
bash examples/proactive/run_sft_warmup.sh
```

### ä» SFT checkpoint å¼€å§‹ RL

```bash
SFT_CKPT="checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/epoch_2"

bash examples/proactive/run_proactive_grpo.sh \
    actor_rollout_ref.model.path="${SFT_CKPT}"
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### Tensorboard

```bash
# SFT è®­ç»ƒ
tensorboard --logdir checkpoints/proactive_sft_warmup/

# RL è®­ç»ƒ
tensorboard --logdir checkpoints/proactive_agent/
```

### æ£€æŸ¥ Checkpoints

```bash
# SFT checkpoints
ls -lh checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/

# RL checkpoints
ls -lh checkpoints/proactive_agent/sft50_rl_beta0.5_n16/
```

## ğŸ“ å®éªŒå»ºè®®

### å¯¹æ¯”å®éªŒ

#### å®éªŒ 1ï¼šä¸åŒ SFT æ ·æœ¬æ•°é‡

```bash
# 25 samples
NUM_SFT_SAMPLES=25 bash examples/proactive/run_sft_then_rl.sh

# 50 samplesï¼ˆæ¨èï¼‰
NUM_SFT_SAMPLES=50 bash examples/proactive/run_sft_then_rl.sh

# 100 samples
NUM_SFT_SAMPLES=100 bash examples/proactive/run_sft_then_rl.sh
```

#### å®éªŒ 2ï¼šæœ‰æ—  SFT å†·å¯åŠ¨

```bash
# æœ‰ SFTï¼ˆæ¨èï¼‰
bash examples/proactive/run_sft_then_rl.sh

# æ—  SFTï¼ˆbaselineï¼‰
bash examples/proactive/run_proactive_grpo.sh
```

#### å®éªŒ 3ï¼šä¸åŒ beta å€¼

```bash
# ä½ betaï¼ˆä¸é¼“åŠ± proactiveï¼‰
bash examples/proactive/run_sft_then_rl.sh \
    custom_reward_function.reward_kwargs.beta=0.3

# ä¸­ betaï¼ˆå¹³è¡¡ï¼‰
bash examples/proactive/run_sft_then_rl.sh \
    custom_reward_function.reward_kwargs.beta=0.5

# é«˜ betaï¼ˆå¼ºçƒˆé¼“åŠ± proactiveï¼‰
bash examples/proactive/run_sft_then_rl.sh \
    custom_reward_function.reward_kwargs.beta=0.7
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q: SFT æ•°æ®ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

A: è°ƒæ•´ `NUM_SFT_SAMPLES`ï¼Œæˆ–è€…å‡†å¤‡æ›´å¤šå¸¦æ ‡ç­¾çš„æ•°æ®ã€‚æœ€å°‘å»ºè®® 25 æ¡ã€‚

### Q: SFT è®­ç»ƒå¾ˆå¿«å°±ç»“æŸäº†ï¼Ÿ

A: æ­£å¸¸ã€‚50 æ¡æ•°æ®ï¼Œ2 epochsï¼Œ4 GPU è®­ç»ƒä¼šå¾ˆå¿«ï¼ˆå‡ åˆ†é’Ÿï¼‰ã€‚è¿™åªæ˜¯å†·å¯åŠ¨ã€‚

### Q: å¦‚ä½•çŸ¥é“ SFT æ˜¯å¦æˆåŠŸï¼Ÿ

A: æ£€æŸ¥ SFT checkpoint çš„ç”Ÿæˆï¼š
```bash
# æ‰‹åŠ¨æµ‹è¯•ç”Ÿæˆ
python -c "
from transformers import AutoModelForCausalLM, AutoTokenizer
model = AutoModelForCausalLM.from_pretrained('checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/epoch_2')
tokenizer = AutoTokenizer.from_pretrained('checkpoints/proactive_sft_warmup/sft_50_samples/checkpoints/epoch_2')
# æµ‹è¯•ç”Ÿæˆ...
"
```

### Q: RL è®­ç»ƒå¯ä»¥è·³è¿‡ SFT å—ï¼Ÿ

A: å¯ä»¥ï¼Œä½†ä¸æ¨èã€‚æ²¡æœ‰ SFTï¼Œæ¨¡å‹ä¸çŸ¥é“å¦‚ä½•ä½¿ç”¨æ ‡ç­¾ï¼ŒRL æ•ˆæœä¼šå·®å¾ˆå¤šã€‚

### Q: ä¸¤ä¸ªæ•°æ®é›†å¯ä»¥åˆå¹¶å—ï¼Ÿ

A: ä¸å»ºè®®ã€‚å®ƒä»¬ç”¨é€”ä¸åŒï¼š
- SFT æ•°æ®ï¼šæ•™æ ¼å¼å’ŒåŸºç¡€èƒ½åŠ›
- RL æ•°æ®ï¼šä¼˜åŒ–ç”Ÿæˆç­–ç•¥

## ğŸ” éªŒè¯ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œç”Ÿæˆåº”è¯¥ç±»ä¼¼ï¼š

```
User: How much money was...?

Model:
<think>
This is a specific legal case question...
</think>

<proactive>
I don't have access to detailed legal records...
</proactive>

I don't have the exact financial details. Please consult legal records.
```

å…³é”®æŒ‡æ ‡ï¼š
- âœ… ä½¿ç”¨äº† `<think>` å’Œ `<proactive>` æ ‡ç­¾
- âœ… ç»“æ„æ¸…æ™°
- âœ… Proactive å†…å®¹åˆç†ï¼ˆæ‰¿è®¤ä¸ç¡®å®šæ€§ï¼‰
- âœ… æ­£å¼å›ç­”ç®€æ´æ˜äº†

## ğŸ“š å‚è€ƒ

- [Group-Aware Reward Manager](./README.md)
- [GRPO Paper](https://arxiv.org/abs/2402.03300)
- [veRL Documentation](https://github.com/volcengine/verl)
